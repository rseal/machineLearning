---
title: 'Machine Learning Course : Exercise Prediction'
author: "Ryan Seal"
date: "November 22, 2015"
output: html_document
bibliography: bibliography.bib
---

#Introduction
The purpose of this project was to take open-source data collected from a variety of exercise-monitoring devices and build a model that can correctly predict when the subject under test has performed a bicep curl correctly. In this data set, there are 6 devised methods used to perform the curl, with only one being correct. Here is a summary of the methods used:

* Class A : correctly performed curl according to specification,
* Class B : incorrectly performed curl throwing elbows out to the front
* Class C : incorrectly lifting the dumbbell half-way up.
* Class D : incorrectly lowering the dumbbell half-way down.
* Class E : incorrectly throwing the hips into the curl. 

These movements were monitored using a set of accelerometers mounted in the following locations:

* glove,
* armband,
* lumbar belt, and
* dumbbell. 

Without any other knowledge, this information alone should be able to provide great insight into a proper prediction. 
#Model ConstructionQualitative Activity Recognition of Weight Lifting Exercises
In this particular set of data, the data is formatted as comma-separated-value (CSV) data, and both training and test data have already been selected. There are several variables provided in the dataset and a list is provided below:
```{r,echo=FALSE}
library(caret)
training <- read.csv('pml-training.csv', na.strings=c('#DIV/0', '', 'NA'), stringsAsFactors = T)
testing <- read.csv('pml-testing.csv', na.strings=c('#DIV/0', '', 'NA'), stringsAsFactors = T)
set.seed(12345)
```
Features were selected by iterating through subsets of data visualized via the \emph{featurePlot} command. After a cursory examination, non-sparse variables were chosen and they were transformed by computing magnitudes of multi-axis data and used 10*log10(var+1) to provide better separation of the values. The following snippet provides a summary of steps taken. 

```{r}
train_features <- NULL
train_features$gbm <- sqrt(training$gyros_belt_x**2.0 + training$gyros_belt_y**2.0 + training$gyros_belt_z**2.0)
train_features$abm <- sqrt(training$accel_belt_x**2.0 + training$accel_belt_y**2.0 + training$accel_belt_z**2.0)
train_features$mbm <- sqrt(training$magnet_belt_x**2.0 + training$magnet_belt_y**2.0 + training$magnet_belt_z**2.0)
train_features$gdm <- sqrt(training$gyros_dumbbell_x**2.0 + training$gyros_dumbbell_y**2.0 + training$gyros_dumbbell_z**2.0)
train_features$adm <- sqrt(training$accel_dumbbell_x**2.0 + training$accel_dumbbell_y**2.0 + training$accel_dumbbell_z**2.0)
train_features$mdm <- sqrt(training$magnet_dumbbell_x**2.0 + training$magnet_dumbbell_y**2.0 + training$magnet_dumbbell_z**2.0)
train_features$roll_belt <- training$roll_belt
train_features$roll_dumbbell <- training$roll_dumbbell
train_features$classe <- training$classe
train_features$pitch_belt <- training$pitch_belt
```
Based on course experience, a random forest algorithm was used to build the prediction model. Variable importance was examined using \emph{varImpPlot} to ensure that the chosen variables provided some level of importance. The number of trees in the fit was limited to 2000.
```{r}
library(randomForest)
fit <- randomForest(classe~.,data=train_features, importance=TRUE)
varImpPlot(fit)
print(fit)
```
Testing data was transformed and the model was applied. 
```{r}
test_features <- NULL
test_features$gbm <- sqrt(testing$gyros_belt_x**2.0 + testing$gyros_belt_y**2.0 + testing$gyros_belt_z**2.0)
test_features$abm <- sqrt(testing$accel_belt_x**2.0 + testing$accel_belt_y**2.0 + testing$accel_belt_z**2.0)
test_features$mbm <- sqrt(testing$magnet_belt_x**2.0 + testing$magnet_belt_y**2.0 + testing$magnet_belt_z**2.0)
test_features$gdm <- sqrt(testing$gyros_dumbbell_x**2.0 + testing$gyros_dumbbell_y**2.0 + testing$gyros_dumbbell_z**2.0)
test_features$adm <- sqrt(testing$accel_dumbbell_x**2.0 + testing$accel_dumbbell_y**2.0 + testing$accel_dumbbell_z**2.0)
test_features$mdm <- sqrt(testing$magnet_dumbbell_x**2.0 + testing$magnet_dumbbell_y**2.0 + testing$magnet_dumbbell_z**2.0)
test_features$roll_belt <- testing$roll_belt
test_features$roll_dumbbell <- testing$roll_dumbbell
test_features$pitch_belt <- testing$pitch_belt
test_features$classe <- testing$classe
```
Testing values were written out for evaluation using the suggested snippet:
```{r}
results <- predict(fit, test_features)

for(i in 1:length(results)){
    filename = paste0("results/problem_id_",i,".txt")
    write.table(results[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
  }
```